{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the mnist dataset from keras which 28x28 images of handwritten numbers from 0-9\n",
    "mnist=tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#dividing the imported data as training and test set\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizing the data between 0 to 1 as the pixel data is 0-255 and normalizing makes it easier and faster for network to learn\n",
    "#makes the learning faster as well\n",
    "x_train_normalized= tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test_normalized= tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:1539395951.4835167\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2670 - acc: 0.9199\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1099 - acc: 0.9668\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0740 - acc: 0.9766\n",
      "end time:1539395965.9569485\n"
     ]
    }
   ],
   "source": [
    "print('Start time:'+str(time.time()))\n",
    "#Building the sequential model which is feed forward\n",
    "model=tf.keras.models.Sequential()\n",
    "\n",
    "#converting the 28x28 multidimensional array into a flat array\n",
    "#instead of keras flatten we can also use numpy reshape\n",
    "#the input layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#now taking the hidden layer as dense layer with 128 units/neuron and rectified linear as activation function\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "\n",
    "#adding the second hidden layer\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "\n",
    "#adding the output layer where the o. of units will be number of classification i.e 10\n",
    "#using softmax in output layer for probability distribution\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "#initializing the hyperparameters\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "#epoch is used to define the number of times we want the neural network to go over the dataset\n",
    "model.fit(x_train_normalized,y_train,epochs=3)\n",
    "print('end time:'+str(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09565742212943733, 0.9707]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running the built model over the test dataset\n",
    "model.evaluate(x_test_normalized,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving the used model\n",
    "model.save('C:/Users/Nikhar/Downloads/Side_work/TensorFlow/project/model/mnist_normalized.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load=tf.keras.models.load_model('C:/Users/Nikhar/Downloads/Side_work/TensorFlow/project/model/mnist_normalized.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09565742212943733, 0.9707]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_load.evaluate(x_test_normalized,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADMBJREFUeJzt3X+IXfWZx/H3s7Otf2jxB45jtGpq\nEbMirF0GXXRds4pil2KsUGn+qFFKU/AHFopsELH+4UJc1nYVlkK6CUZobQutPxDRRll/wVIcJTR2\n3d2KjG02IZlBRfuPxfjsH3PTnercM+P9de7keb8g3HvPc+75PhzymXPuPffeb2Qmkur5s7YbkNQO\nwy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qag/H+VgJ554Yq5du3aUQ0qlzM7OMj8/HytZt6/w\nR8SVwH3ABPBvmbm1af21a9cyMzPTz5CSGkxPT6943Z5P+yNiAvhX4IvAOcDGiDin1+1JGq1+XvOf\nD7yemW9k5h+AHwMbBtOWpGHrJ/ynAr9b9HhvZ9mfiIjNETETETNzc3N9DCdpkPoJ/1JvKnzs+8GZ\nuS0zpzNzenJyso/hJA1SP+HfC5y26PFngX39tSNpVPoJ/0vAWRHxuYj4NPBV4LHBtCVp2Hq+1JeZ\nH0TEzcBTLFzq25GZvx5YZ5KGqq/r/Jn5BPDEgHqRNEJ+vFcqyvBLRRl+qSjDLxVl+KWiDL9UlOGX\nijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJTh\nl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWi+pqlNyJmgfeAQ8AHmTk9iKYkgLvvvruxfueddzbWM7Nr\n7dlnn2187iWXXNJYPxL0Ff6Ov8vM+QFsR9IIedovFdVv+BP4RUS8HBGbB9GQpNHo97T/oszcFxEn\nAbsi4r8y8/nFK3T+KGwGOP300/scTtKg9HXkz8x9nduDwMPA+Uussy0zpzNzenJysp/hJA1Qz+GP\niKMj4jOH7wNXAK8OqjFJw9XPaf8U8HBEHN7OjzLzyYF0JWnoeg5/Zr4B/OUAe1ExDzzwQGN969at\njfWJiYnG+qFDh7rWOget0rzUJxVl+KWiDL9UlOGXijL8UlGGXypqEN/qk3ry5ptvNtbff//9EXVS\nk0d+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK6/waqqeffrpr7f777+9r2+vWrWusP/74411rU1NT\nfY19JPDILxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFeZ1ffXnxxRcb69dff33X2rvvvtvX2Lfddltj\n/Ywzzuhr+0c6j/xSUYZfKsrwS0UZfqkowy8VZfilogy/VNSy1/kjYgfwJeBgZp7bWXYC8BNgLTAL\nXJuZbw+vTY2rnTt3Ntb37dvX87bXr1/fWL/uuut63rZWduR/ALjyI8u2AM9k5lnAM53HklaRZcOf\nmc8Db31k8Qbg8J/8ncDVA+5L0pD1+pp/KjP3A3RuTxpcS5JGYehv+EXE5oiYiYiZubm5YQ8naYV6\nDf+BiFgD0Lk92G3FzNyWmdOZOT05OdnjcJIGrdfwPwZs6tzfBDw6mHYkjcqy4Y+Ih4D/AM6OiL0R\n8XVgK3B5RPwGuLzzWNIqsux1/szc2KV02YB70Rian59vrG/fvr2xPjEx0bV23HHHNT73jjvuaKyr\nP37CTyrK8EtFGX6pKMMvFWX4paIMv1SUP91d3OzsbGP9mmuuGdrYt9xyS2P90ksvHdrY8sgvlWX4\npaIMv1SU4ZeKMvxSUYZfKsrwS0V5nb+4J598srG+Z8+evrZ/2WXdv/l966239rVt9ccjv1SU4ZeK\nMvxSUYZfKsrwS0UZfqkowy8V5XX+I9wjjzzSWN+ypb8Jli+++OLGetMU3scee2xfY6s/Hvmlogy/\nVJThl4oy/FJRhl8qyvBLRRl+qahlr/NHxA7gS8DBzDy3s+wu4BvAXGe12zPziWE1qWZNv70/zN/d\nBzjzzDMb61NTU0MdX71byZH/AeDKJZZ/LzPP6/wz+NIqs2z4M/N54K0R9CJphPp5zX9zRPwqInZE\nxPED60jSSPQa/u8DnwfOA/YD93ZbMSI2R8RMRMzMzc11W03SiPUU/sw8kJmHMvND4AfA+Q3rbsvM\n6cycnpyc7LVPSQPWU/gjYs2ih18GXh1MO5JGZSWX+h4C1gMnRsRe4DvA+og4D0hgFvjmEHuUNATL\nhj8zNy6xePsQelGP7rnnnq61iYmJoY7d7+8BqD1+wk8qyvBLRRl+qSjDLxVl+KWiDL9UlD/dvQrs\n3r27sf7UU08NbeyrrrqqsX722WcPbWwNl0d+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK6/yrwBVX\nXNFYf/vtt3ve9gUXXNBYb5piW6ubR36pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrr/KvA/Px8Y72f\nn+e+6aabGuvHHHNMz9vWePPILxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFLXudPyJOAx4ETgY+BLZl\n5n0RcQLwE2AtMAtcm5m9f7G8sBtuuKGxnpmN9UOHDvU89oUXXtjzc7W6reTI/wHw7cz8C+CvgZsi\n4hxgC/BMZp4FPNN5LGmVWDb8mbk/M1/p3H8PeA04FdgAHP6Zl53A1cNqUtLgfaLX/BGxFvgC8Etg\nKjP3w8IfCOCkQTcnaXhWHP6IOAb4GfCtzHz3Ezxvc0TMRMTM3NxcLz1KGoIVhT8iPsVC8H+YmT/v\nLD4QEWs69TXAwaWem5nbMnM6M6cnJycH0bOkAVg2/BERwHbgtcz87qLSY8Cmzv1NwKODb0/SsKzk\nK70XAV8D9kTE4bmibwe2Aj+NiK8DvwW+MpwWV7/lptjetWtXY33h7293Rx11VNfajTfe2Pjcqamp\nxrqOXMuGPzNfBLr977tssO1IGhU/4ScVZfilogy/VJThl4oy/FJRhl8qyp/uHoF33nmnsX7gwIG+\ntn/KKad0rd177719bVtHLo/8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZ\nfqkowy8VZfilogy/VJTf5x+BdevWNdaXmyb7hRdeGGQ7EuCRXyrL8EtFGX6pKMMvFWX4paIMv1SU\n4ZeKWvY6f0ScBjwInAx8CGzLzPsi4i7gG8BcZ9XbM/OJYTW6mp188smN9eeee25EnUj/byUf8vkA\n+HZmvhIRnwFejohdndr3MvOfh9eepGFZNvyZuR/Y37n/XkS8Bpw67MYkDdcnes0fEWuBLwC/7Cy6\nOSJ+FRE7IuL4Ls/ZHBEzETEzNze31CqSWrDi8EfEMcDPgG9l5rvA94HPA+excGaw5KRwmbktM6cz\nc3pycnIALUsahBWFPyI+xULwf5iZPwfIzAOZeSgzPwR+AJw/vDYlDdqy4Y+IALYDr2XmdxctX7No\ntS8Drw6+PUnDspJ3+y8CvgbsiYjdnWW3Axsj4jwggVngm0PpUNJQrOTd/heBWKLkNX1pFfMTflJR\nhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIiM0c3WMQc8Oai\nRScC8yNr4JMZ197GtS+wt14NsrczMnNFv5c30vB/bPCImcycbq2BBuPa27j2BfbWq7Z687RfKsrw\nS0W1Hf5tLY/fZFx7G9e+wN561Upvrb7ml9Seto/8klrSSvgj4sqI+O+IeD0itrTRQzcRMRsReyJi\nd0TMtNzLjog4GBGvLlp2QkTsiojfdG6XnCatpd7uioj/7ey73RHx9y31dlpE/HtEvBYRv46IWzvL\nW913DX21st9GftofERPA/wCXA3uBl4CNmfmfI22ki4iYBaYzs/VrwhHxt8DvgQcz89zOsn8C3srM\nrZ0/nMdn5j+MSW93Ab9ve+bmzoQyaxbPLA1cDVxPi/uuoa9raWG/tXHkPx94PTPfyMw/AD8GNrTQ\nx9jLzOeBtz6yeAOws3N/Jwv/eUauS29jITP3Z+YrnfvvAYdnlm513zX01Yo2wn8q8LtFj/cyXlN+\nJ/CLiHg5Ija33cwSpjrTph+ePv2klvv5qGVnbh6lj8wsPTb7rpcZrwetjfAvNfvPOF1yuCgz/wr4\nInBT5/RWK7OimZtHZYmZpcdCrzNeD1ob4d8LnLbo8WeBfS30saTM3Ne5PQg8zPjNPnzg8CSpnduD\nLffzR+M0c/NSM0szBvtunGa8biP8LwFnRcTnIuLTwFeBx1ro42Mi4ujOGzFExNHAFYzf7MOPAZs6\n9zcBj7bYy58Yl5mbu80sTcv7btxmvG7lQz6dSxn/AkwAOzLzH0fexBIi4kwWjvawMInpj9rsLSIe\nAtaz8K2vA8B3gEeAnwKnA78FvpKZI3/jrUtv61k4df3jzM2HX2OPuLe/AV4A9gAfdhbfzsLr69b2\nXUNfG2lhv/kJP6koP+EnFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqmo/wOwvY+JjyoCowAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218cb7f8898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking the downloaded data\n",
    "#cmap=plt.cm.binary shows the image in black and white\n",
    "plt.imshow(x_train[3],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
